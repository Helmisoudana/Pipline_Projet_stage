# ğŸ¯ Pipeline de VÃ©rification d'Articles

Ce projet est un **pipeline d'analyse automatique** des articles commerciaux, qui dÃ©tecte plusieurs types dâ€™anomalies :
- Champs vides
- Duplications
- Erreurs de code
- Anomalies dÃ©tectÃ©es via modÃ¨le Machine Learning (scikit-learn)

Les articles sont rÃ©cupÃ©rÃ©s via une API et les anomalies sont enregistrÃ©es dans une base de donnÃ©es SQL.

---

## ğŸ“ Structure du projet
NafNafSystem/
â”‚
â”œâ”€â”€ main.py # DÃ©marrage FastAPI et scheduler
â”œâ”€â”€ verification/
â”‚ â”œâ”€â”€ pipline.py # ExÃ©cution du pipeline complet
â”‚ â”œâ”€â”€ fetchdata.py # RÃ©cupÃ©ration des articles depuis une API
â”‚ â”œâ”€â”€ fetchdata_withJson.py # RÃ©cupÃ©ration via JSON POST
â”‚ â”œâ”€â”€ verif_duplication.py # DÃ©tection de doublons
â”‚ â”œâ”€â”€ verifnull.py # DÃ©tection de champs vides
â”‚ â”œâ”€â”€ VerifCode.py # VÃ©rification des formats de code
â”‚ â””â”€â”€ detect_avec_model.py # DÃ©tection via modÃ¨le ML
â”‚
â”œâ”€â”€ models/ # ModÃ¨les SQLModel (Article, Anomalie, etc.)
â”œâ”€â”€ database/ # Configuration de la session SQLModel
â”‚
â”œâ”€â”€ .env # Variables dâ€™environnement
â”œâ”€â”€ requirements.txt # DÃ©pendances Python
â””â”€â”€ README.md # Ce fichier

---

## ğŸš€ Comment exÃ©cuter le projet

### 1. Cloner le dÃ©pÃ´t
2. CrÃ©er un environnement virtuel
bash
Copier
Modifier
python -m venv venv
# Linux/macOS
source venv/bin/activate
# Windows
venv\Scripts\activate
3. Installer les dÃ©pendances
bash
Copier
Modifier
pip install -r requirements.txt
âš™ï¸ Configuration .env
CrÃ©e un fichier .env Ã  la racine du projet avec le contenu suivant :

env
Copier
Modifier
API_URL=http://127.0.0.1:8000/article/
API_URL_BY_ID=http://127.0.0.1:8000/article/by_ids
MONGODB_URL=mongodb://localhost:27017
MYSQL_URL=mysql+mysqlconnector://root:password@localhost:3306/nom_de_ta_base
ğŸ”§ Remplace password et nom_de_ta_base par les valeurs de ta configuration locale.

ğŸ§  Technologies utilisÃ©es
FastAPI â€“ Framework web rapide pour APIs

SQLModel â€“ ORM basÃ© sur SQLAlchemy + Pydantic

APScheduler â€“ ExÃ©cution automatique du pipeline pÃ©riodiquement

Scikit-learn â€“ ModÃ¨le de dÃ©tection dâ€™anomalies

pymongo â€“ Connexion MongoDB (optionnel)

requests â€“ RequÃªtes HTTP vers API distante

python-dotenv â€“ Gestion des variables dâ€™environnement

â–¶ï¸ Lancer l'application
bash
Copier
Modifier
uvicorn main:app --reload
DÃ©marre le serveur FastAPI et le scheduler (le pipeline sâ€™exÃ©cute toutes les 2 heures automatiquement).

ğŸ§ª Endpoints utiles
MÃ©thode	URL	Description
POST	/article/import	Importation par JSON (liste d'IDs)
GET	/article/	RÃ©cupÃ¨re tous les articles disponibles
POST	/pipeline/run	Lance manuellement le pipeline

âœï¸ Auteur
Helmi Soudana
ğŸ“ ENISo, Tunisie
ğŸ“§ helmi.soudana@example.com

